import numpy as np
import matplotlib.pyplot as plt
import json
import os
import pandas as pd
from .welfare_evaluation import evaluate_welfare_cost

# Pipeline colors
PIPELINE_COLORS = {
    'Socially_Fair_Python': 'blue',
    'Welfare_Clustering': 'green',
    'Fair-Clustering-Under-Bounded-Cost': 'red'
}

# Pipeline markers
PIPELINE_MARKERS = {
    'Socially_Fair_Python': 'o',
    'Welfare_Clustering': 's',
    'Fair-Clustering-Under-Bounded-Cost': '^'
}

def plot_welfare_costs_comparison(result_files, dataset_name, k, lambda_param, p, save_path=None):
    """
    Plot welfare costs comparison across different pipelines.
    """
    plt.figure(figsize=(10, 6))
    
    for pipeline_name, result_file in result_files.items():
        with open(result_file, 'r') as f:
            results = json.load(f)
        
        k_results = results['results'][str(k)]
        
        # Plot standard clustering results
        if k_results['standard'] is not None:
            plt.scatter(
                [k], 
                [k_results['standard']['metrics']['welfare_cost']],
                label=f'{pipeline_name} (Standard)',
                marker=PIPELINE_MARKERS.get(pipeline_name, 'o'),
                color=PIPELINE_COLORS.get(pipeline_name, 'gray')
            )
        
        # Plot fair clustering results
        if k_results['fair'] is not None:
            plt.scatter(
                [k], 
                [k_results['fair']['metrics']['welfare_cost']],
                label=f'{pipeline_name} (Fair)',
                marker=PIPELINE_MARKERS.get(pipeline_name, 's'),
                color=PIPELINE_COLORS.get(pipeline_name, 'gray')
            )
    
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('Welfare Cost')
    plt.title(f'Welfare Costs Comparison (λ={lambda_param}, p={p})')
    plt.legend()
    plt.grid(True)
    
    if save_path:
        output_dir = os.path.dirname(save_path)
        if output_dir:  # Only try to create directory if there is a directory path
            os.makedirs(output_dir, exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Plot saved to: {save_path}")
    else:
        plt.show()

def load_and_plot_results(result_files, dataset_name, k, lambda_param=0.5, p=2, save_path=None):
    """
    Load results from multiple pipeline output files and plot welfare costs.
    
    Args:
        result_files: dict - keys are pipeline names, values are paths to result files
        dataset_name: str - name of the dataset
        k: int - number of clusters
        lambda_param: float - weight between distance and fairness costs
        p: int - distance metric parameter (1 for k-median, 2 for k-means)
        save_path: str - path to save the plot (optional)
    """
    pipeline_results = {}
    
    for pipeline_name, result_file in result_files.items():
        # Load results from file
        with open(result_file, 'r') as f:
            results = json.load(f)
        
        # Extract necessary components
        pipeline_results[pipeline_name] = {
            'centers': np.array(results['centers']),
            'assignment': np.array(results['assignment']),
            'points': np.array(results['points']),
            'group_labels': np.array(results['group_labels'])
        }
    
    # Plot welfare costs
    plot_welfare_costs_comparison(
        result_files=pipeline_results,
        dataset_name=dataset_name,
        k=k,
        lambda_param=lambda_param,
        p=p,
        save_path=save_path
    )
    
    return pipeline_results

def plot_welfare_costs_from_csv(cache_dir, k_min, k_max, lambda_param, save_path=None):
    """
    Plot welfare costs from CSV files generated by the evaluation scripts.
    
    Args:
        cache_dir: str - directory containing the welfare_evaluation directory
        k_min: int - minimum number of clusters
        k_max: int - maximum number of clusters
        lambda_param: float - weight between distance and fairness costs
        save_path: str - path to save the plot (optional)
    """
    welfare_dir = os.path.join(cache_dir, "welfare_evaluation")
    
    # Check if combined files exist
    combined_files = {
        'Welfare Clustering': f"welfare_clustering_all_k{k_min}_to_{k_max}_welfare_costs.csv",
        'FCBC': f"fcbc_all_k{k_min}_to_{k_max}_welfare_costs.csv",
        'Samira SF': f"samira_sf_all_k{k_min}_to_{k_max}_welfare_costs.csv"
    }
    
    # Check if individual files exist
    individual_files = {
        'Welfare Clustering': [f"welfare_clustering_k{k}_welfare_costs.csv" for k in range(k_min, k_max + 1)],
        'FCBC': [f"fcbc_k{k}_welfare_costs.csv" for k in range(k_min, k_max + 1)],
        'Samira SF': [f"samira_sf_k{k}_welfare_costs.csv" for k in range(k_min, k_max + 1)]
    }
    
    plt.figure(figsize=(12, 8))
    
    for pipeline_name, combined_file in combined_files.items():
        file_path = os.path.join(welfare_dir, combined_file)
        
        # Check if combined file exists
        if os.path.exists(file_path) and os.path.getsize(file_path) > 10:  # Ensure file is not empty
            try:
                # Load results from combined file
                df = pd.read_csv(file_path)
                
                # Filter by lambda_param if it exists in the dataframe
                if 'lambda_param' in df.columns:
                    df = df[df['lambda_param'] == lambda_param]
                
                # Group by k and get the minimum welfare cost for each k
                if 'method' in df.columns:
                    # For Samira SF, we have both standard and fair methods
                    for method in ['standard', 'fair']:
                        method_df = df[df['method'] == method]
                        if not method_df.empty:
                            min_costs = method_df.groupby('k')['max_welfare_cost'].min()
                            plt.plot(
                                min_costs.index, 
                                min_costs.values, 
                                label=f'{pipeline_name} ({method.capitalize()})',
                                marker='o' if method == 'standard' else 's',
                                linestyle='-'
                            )
                else:
                    # For other pipelines, just plot the minimum cost for each k
                    min_costs = df.groupby('k')['max_welfare_cost'].min()
                    plt.plot(
                        min_costs.index, 
                        min_costs.values, 
                        label=pipeline_name,
                        marker='o',
                        linestyle='-'
                    )
                print(f"Loaded data from combined file: {combined_file}")
                continue
            except Exception as e:
                print(f"Error loading combined file {combined_file}: {str(e)}")
        
        # If combined file doesn't exist or is empty, try individual files
        print(f"Trying individual files for {pipeline_name}...")
        all_data = []
        
        for k_file in individual_files[pipeline_name]:
            k_file_path = os.path.join(welfare_dir, k_file)
            if os.path.exists(k_file_path) and os.path.getsize(k_file_path) > 10:  # Ensure file is not empty
                try:
                    k_df = pd.read_csv(k_file_path)
                    
                    # Extract k value from filename
                    k = int(k_file.split('_k')[1].split('_')[0])
                    k_df['k'] = k
                    
                    all_data.append(k_df)
                except Exception as e:
                    print(f"Error loading file {k_file}: {str(e)}")
        
        if all_data:
            # Combine all data
            df = pd.concat(all_data, ignore_index=True)
            
            # Filter by lambda_param if it exists in the dataframe
            if 'lambda_param' in df.columns:
                df = df[df['lambda_param'] == lambda_param]
            
            # Group by k and get the minimum welfare cost for each k
            if 'method' in df.columns:
                # For Samira SF, we have both standard and fair methods
                for method in ['standard', 'fair']:
                    method_df = df[df['method'] == method]
                    if not method_df.empty:
                        min_costs = method_df.groupby('k')['max_welfare_cost'].min()
                        plt.plot(
                            min_costs.index, 
                            min_costs.values, 
                            label=f'{pipeline_name} ({method.capitalize()})',
                            marker='o' if method == 'standard' else 's',
                            linestyle='-'
                        )
            else:
                # For other pipelines, just plot the minimum cost for each k
                min_costs = df.groupby('k')['max_welfare_cost'].min()
                plt.plot(
                    min_costs.index, 
                    min_costs.values, 
                    label=pipeline_name,
                    marker='o',
                    linestyle='-'
                )
            print(f"Loaded data from individual files for {pipeline_name}")
        else:
            print(f"Warning: No data found for {pipeline_name}")
    
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('Welfare Cost')
    plt.title(f'Welfare Costs Comparison (λ={lambda_param})')
    plt.legend()
    plt.grid(True)
    
    if save_path:
        output_dir = os.path.dirname(save_path)
        if output_dir:  # Only try to create directory if there is a directory path
            os.makedirs(output_dir, exist_ok=True)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Plot saved to: {save_path}")
    else:
        plt.show()

# Example usage
if __name__ == "__main__":
    # Example of how to use the plotting functions
    print("Example of how to use the plotting functions:")
    print("\n1. Direct plotting with results:")
    print("pipeline_results = {")
    print("    'Samira_SF_Python': {'centers': centers1, 'assignment': assignment1, 'points': points, 'group_labels': group_labels},")
    print("    'Welfare_Clustering': {'centers': centers2, 'assignment': assignment2, 'points': points, 'group_labels': group_labels},")
    print("    'Fair-Clustering-Under-Bounded-Cost': {'centers': centers3, 'assignment': assignment3, 'points': points, 'group_labels': group_labels}")
    print("}")
    print("plot_welfare_costs_comparison(pipeline_results, 'adult', k=5, lambda_param=0.5, p=2, save_path='welfare_costs.png')")
    
    print("\n2. Loading results from files and plotting:")
    print("result_files = {")
    print("    'Samira_SF_Python': 'path/to/samira_results.json',")
    print("    'Welfare_Clustering': 'path/to/welfare_results.json',")
    print("    'Fair-Clustering-Under-Bounded-Cost': 'path/to/fair_results.json'")
    print("}")
    print("load_and_plot_results(result_files, 'adult', k=5, lambda_param=0.5, p=2, save_path='welfare_costs.png')")
    
    print("\n3. Plotting from CSV files generated by evaluation scripts:")
    print("plot_welfare_costs_from_csv('cache', k_min=4, k_max=8, lambda_param=0.5, save_path='welfare_costs_comparison.png')") 